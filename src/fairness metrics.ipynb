{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51a068b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22d3a4",
   "metadata": {},
   "source": [
    "## Generating data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa0533fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential schools for datapoints \n",
    "schools = ['Brown University', 'Columbia University', 'SUNY Binghamton University', 'SUNY New Paltz',\n",
    "           'Providence College','Rhode Island School of Design', 'Bentley University', 'Colgate University']\n",
    "\n",
    "# potential gpas for datapoints \n",
    "gpa = np.arange(1.2,4.1,0.1,dtype=float)\n",
    "\n",
    "# degree options for datapoints \n",
    "degrees = ['Bachelors','Masters','Phd']\n",
    "\n",
    "# potential locations for datapoints \n",
    "locations = ['Providence','Boston','New York City','Los Angeles','Miami','Chicago', 'Detroit', 'Washington D.C.']\n",
    "\n",
    "# potential genders \n",
    "gender = ['M', 'F', 'N/A']\n",
    "\n",
    "# potential veteran status \n",
    "veteran = ['0','1','N/A']\n",
    "\n",
    "# potential work authorization\n",
    "work_ath = ['0','1']\n",
    "\n",
    "# potential value for disability \n",
    "disability = ['0','1','N/A']\n",
    "\n",
    "# potential ethnicities \n",
    "ethnicity = ['0','1','2','3','4']\n",
    "\n",
    "# potential roles \n",
    "roles = ['Junior SWE', 'Senior SWE','Data scientist','Lawyer','ML Engineer','N/A', 'Chef','Bus Driver']\n",
    "\n",
    "# master list for all attributes not include roles \n",
    "candidate_atts = [schools, gpa, degrees, locations, gender, veteran, work_ath, disability, ethnicity]\n",
    "\n",
    "# columns for dataframe \n",
    "COLUMNS = ['School Name','GPA','Degree','Location','Gender',\n",
    "        'Veteran status','Work authorization','Disability','Ethnicity',\n",
    "        'Role 1', 'Start 1', 'End 1','Role 2','Start 2','End 2','Role 3','Start 3','End 3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e375c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MONTHS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "COLUMNS = ['School Name', 'GPA', 'Degree', 'Location', 'Gender',\n",
    "           'Veteran status', 'Work authorization', 'Disability', 'Ethnicity',\n",
    "           'Role 1', 'Start 1', 'End 1', 'Role 2', 'Start 2', 'End 2', 'Role 3', 'Start 3', 'End 3']\n",
    "\n",
    "def generate_data(n_samples: int, candidate_atts: list, roles: list) -> pd.DataFrame:\n",
    "    all_candidates = []  # List for all datapoints\n",
    "\n",
    "    # Generate for each datapoint\n",
    "    for i in range(n_samples):\n",
    "        candidate = [i + 1]  # New candidate starting with Applicant ID\n",
    "\n",
    "        # Loop through each attribute type for given candidate\n",
    "        for attribute in candidate_atts:\n",
    "            # Pick random attribute from list\n",
    "            candidate.append(attribute[np.random.randint(0, len(attribute))])\n",
    "\n",
    "        # Generate role types\n",
    "        cand_roles = [roles[np.random.randint(0, len(roles))] for _ in range(3)]\n",
    "        role_history = []  # Candidates job history\n",
    "\n",
    "        # Loop through candidate roles to populate dates\n",
    "        for index, role in enumerate(cand_roles):\n",
    "            if role == 'N/A':\n",
    "                while len(role_history) != 9:\n",
    "                    role_history.append('N/A')\n",
    "                break\n",
    "            else:\n",
    "                start_month = MONTHS[np.random.randint(0, len(MONTHS))]\n",
    "                end_month = start_month  # Initialize end_month same as start_month\n",
    "\n",
    "                start_year = np.random.randint(10, 24)\n",
    "                range_high = 23 - start_year\n",
    "                if range_high <= 0:  # Safeguard against low >= high\n",
    "                    end_year = 23  # Set to max year if no range is available\n",
    "                else:\n",
    "                    end_year = start_year + np.random.randint(0, range_high)\n",
    "\n",
    "                # If the start year equals the end year, adjust the end month to be after the start month\n",
    "                if start_year == end_year:\n",
    "                    if start_month == 12:  # Special case where start month is December\n",
    "                        end_month = 1\n",
    "                        end_year += 1  # Increment the year if end month cannot be later\n",
    "                    else:\n",
    "                        end_month = np.random.randint(start_month + 1, 13)\n",
    "\n",
    "                start = f\"{start_month}/{start_year}\"\n",
    "                if index == 0 and np.random.rand() < 0.1:  # 10% chance to end as 'N/A'\n",
    "                    end = 'N/A'\n",
    "                else:\n",
    "                    end = f\"{end_month}/{end_year}\"\n",
    "\n",
    "                role_history.append(role)\n",
    "                role_history.append(start)\n",
    "                role_history.append(end)\n",
    "\n",
    "        candidate.extend(role_history)\n",
    "        all_candidates.append(candidate)\n",
    "\n",
    "    # Insert columns including Applicant ID at the start\n",
    "    columns_with_id = ['Applicant ID'] + COLUMNS\n",
    "    df = pd.DataFrame(all_candidates, columns=columns_with_id)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate the DataFrame\n",
    "df = generate_data(4000, candidate_atts, roles)\n",
    "\n",
    "# Convert DataFrame to JSON, one dictionary per row\n",
    "dataset_json = df.to_json(orient='records') #str type\n",
    "dataset_json = json.loads(dataset_json) #list type\n",
    "# print(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ede53fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Applicant ID                    School Name  GPA     Degree       Location  \\\n",
      "0             1  Rhode Island School of Design  2.5  Bachelors     Providence   \n",
      "1             2             Colgate University  2.2  Bachelors        Detroit   \n",
      "2             3     SUNY Binghamton University  3.8    Masters  New York City   \n",
      "3             4            Columbia University  2.2        Phd        Detroit   \n",
      "4             5            Columbia University  2.6    Masters         Boston   \n",
      "\n",
      "  Gender Veteran status Work authorization Disability Ethnicity  \\\n",
      "0      M              1                  0          0         0   \n",
      "1      F              1                  0          0         4   \n",
      "2    N/A            N/A                  1          1         3   \n",
      "3    N/A              0                  0          1         4   \n",
      "4      F              1                  0          0         2   \n",
      "\n",
      "           Role 1 Start 1  End 1       Role 2 Start 2  End 2          Role 3  \\\n",
      "0  Data scientist    2/23   9/23   Senior SWE    2/22   6/22     ML Engineer   \n",
      "1  Data scientist    7/20  12/20   Bus Driver    8/11   8/19          Lawyer   \n",
      "2            Chef    2/21  12/21  ML Engineer    7/17   7/20      Senior SWE   \n",
      "3  Data scientist    6/10   6/21   Bus Driver   11/11  11/13      Senior SWE   \n",
      "4          Lawyer   12/11   1/12       Lawyer    1/18   5/18  Data scientist   \n",
      "\n",
      "  Start 3  End 3  \n",
      "0   10/22  12/22  \n",
      "1    7/15   7/16  \n",
      "2    5/15   5/19  \n",
      "3    6/10   6/12  \n",
      "4   12/10  12/22  \n",
      "Applicant ID            int64\n",
      "School Name            object\n",
      "GPA                   float64\n",
      "Degree                 object\n",
      "Location               object\n",
      "Gender                 object\n",
      "Veteran status         object\n",
      "Work authorization     object\n",
      "Disability             object\n",
      "Ethnicity              object\n",
      "Role 1                 object\n",
      "Start 1                object\n",
      "End 1                  object\n",
      "Role 2                 object\n",
      "Start 2                object\n",
      "End 2                  object\n",
      "Role 3                 object\n",
      "Start 3                object\n",
      "End 3                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611ff93",
   "metadata": {},
   "source": [
    "## Sending requests to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43bf9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(data_original):\n",
    "    \n",
    "    data = data_original.copy()\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data['GPA'] = data['GPA'].apply(lambda x: f\"{x:.2f}\")\n",
    "        data = data.to_dict(orient='records')\n",
    "    # Serialize the input data to JSON\n",
    "    dataset = json.dumps(data)\n",
    "    \n",
    "    # Define the headers for JSON content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Call the first API - resume scorer\n",
    "    resume_url = 'https://jennjwang.pythonanywhere.com'\n",
    "    resume_response = requests.post(resume_url, data=dataset, headers=headers)\n",
    "    \n",
    "    if not resume_response.ok:\n",
    "        print(\"Error:\", resume_response.status_code)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        resume_response_data = json.loads(resume_response.text)\n",
    "        resume_predictions = json.loads(resume_response_data['prediction'])\n",
    "        resume_score_map = {item['applicant_id']: item['score'] for item in resume_predictions}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error decoding JSON:\", e)\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # Update the input data with the resume score\n",
    "    for applicant in data:\n",
    "        applicant_id = str(applicant['Applicant ID'])\n",
    "        applicant['Resume score'] = resume_score_map.get(applicant_id, 0)\n",
    "    \n",
    "    # Serialize the updated data for the next API call\n",
    "    updated_dataset = json.dumps(data)\n",
    "    \n",
    "    # Call the second API - candidate scorer\n",
    "    candidate_url = 'https://heonlee.pythonanywhere.com'\n",
    "    candidate_response = requests.post(candidate_url, data=updated_dataset, headers=headers)\n",
    "    \n",
    "    if not candidate_response.ok:\n",
    "        print(\"Error:\", candidate_response.status_code)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        candidate_response_data = json.loads(candidate_response.text)\n",
    "        final_predictions = json.loads(candidate_response_data['prediction'])\n",
    "        final_score_map = {item['applicant_id']: item['prediction'] for item in final_predictions}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error decoding JSON for the second API:\", e)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    for applicant in data:\n",
    "        applicant_id = str(applicant['Applicant ID'])\n",
    "        applicant['Interview prediction'] = final_score_map.get(applicant_id, 0)\n",
    "        \n",
    "    results = pd.DataFrame(data)\n",
    "    results['GPA'] = results['GPA'].astype(float)\n",
    "    results['Resume score'] = results['Resume score'].astype(float)\n",
    "    results['Interview prediction'] = results['Interview prediction'].astype(int)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a864496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applicant ID</th>\n",
       "      <th>School Name</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Location</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Veteran status</th>\n",
       "      <th>Work authorization</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>Start 1</th>\n",
       "      <th>End 1</th>\n",
       "      <th>Role 2</th>\n",
       "      <th>Start 2</th>\n",
       "      <th>End 2</th>\n",
       "      <th>Role 3</th>\n",
       "      <th>Start 3</th>\n",
       "      <th>End 3</th>\n",
       "      <th>Resume score</th>\n",
       "      <th>Interview prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rhode Island School of Design</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Providence</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2/23</td>\n",
       "      <td>9/23</td>\n",
       "      <td>Senior SWE</td>\n",
       "      <td>2/22</td>\n",
       "      <td>6/22</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>10/22</td>\n",
       "      <td>12/22</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Colgate University</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7/20</td>\n",
       "      <td>12/20</td>\n",
       "      <td>Bus Driver</td>\n",
       "      <td>8/11</td>\n",
       "      <td>8/19</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>7/15</td>\n",
       "      <td>7/16</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SUNY Binghamton University</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Masters</td>\n",
       "      <td>New York City</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2/21</td>\n",
       "      <td>12/21</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>7/17</td>\n",
       "      <td>7/20</td>\n",
       "      <td>Senior SWE</td>\n",
       "      <td>5/15</td>\n",
       "      <td>5/19</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Phd</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6/10</td>\n",
       "      <td>6/21</td>\n",
       "      <td>Bus Driver</td>\n",
       "      <td>11/11</td>\n",
       "      <td>11/13</td>\n",
       "      <td>Senior SWE</td>\n",
       "      <td>6/10</td>\n",
       "      <td>6/12</td>\n",
       "      <td>9.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Boston</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12/11</td>\n",
       "      <td>1/12</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>1/18</td>\n",
       "      <td>5/18</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>12/10</td>\n",
       "      <td>12/22</td>\n",
       "      <td>5.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3996</td>\n",
       "      <td>Bentley University</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Providence</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4/14</td>\n",
       "      <td>4/22</td>\n",
       "      <td>Junior SWE</td>\n",
       "      <td>10/13</td>\n",
       "      <td>10/19</td>\n",
       "      <td>Junior SWE</td>\n",
       "      <td>8/22</td>\n",
       "      <td>10/22</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3997</td>\n",
       "      <td>SUNY New Paltz</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3998</td>\n",
       "      <td>Colgate University</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Boston</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2/10</td>\n",
       "      <td>2/20</td>\n",
       "      <td>Bus Driver</td>\n",
       "      <td>7/20</td>\n",
       "      <td>7/22</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>12/12</td>\n",
       "      <td>12/18</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3999</td>\n",
       "      <td>Bentley University</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2/15</td>\n",
       "      <td>2/17</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>8/23</td>\n",
       "      <td>11/23</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>12/18</td>\n",
       "      <td>12/19</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4000</td>\n",
       "      <td>SUNY Binghamton University</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Boston</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1/20</td>\n",
       "      <td>11/20</td>\n",
       "      <td>Senior SWE</td>\n",
       "      <td>4/20</td>\n",
       "      <td>4/22</td>\n",
       "      <td>Bus Driver</td>\n",
       "      <td>7/14</td>\n",
       "      <td>7/19</td>\n",
       "      <td>9.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Applicant ID                    School Name  GPA     Degree  \\\n",
       "0                1  Rhode Island School of Design  2.5  Bachelors   \n",
       "1                2             Colgate University  2.2  Bachelors   \n",
       "2                3     SUNY Binghamton University  3.8    Masters   \n",
       "3                4            Columbia University  2.2        Phd   \n",
       "4                5            Columbia University  2.6    Masters   \n",
       "...            ...                            ...  ...        ...   \n",
       "3995          3996             Bentley University  3.0    Masters   \n",
       "3996          3997                 SUNY New Paltz  1.7    Masters   \n",
       "3997          3998             Colgate University  3.5  Bachelors   \n",
       "3998          3999             Bentley University  3.2    Masters   \n",
       "3999          4000     SUNY Binghamton University  1.7    Masters   \n",
       "\n",
       "             Location Gender Veteran status Work authorization Disability  \\\n",
       "0          Providence      M              1                  0          0   \n",
       "1             Detroit      F              1                  0          0   \n",
       "2       New York City    N/A            N/A                  1          1   \n",
       "3             Detroit    N/A              0                  0          1   \n",
       "4              Boston      F              1                  0          0   \n",
       "...               ...    ...            ...                ...        ...   \n",
       "3995       Providence      F              0                  1          0   \n",
       "3996          Detroit    N/A            N/A                  0          0   \n",
       "3997           Boston    N/A            N/A                  1          1   \n",
       "3998  Washington D.C.    N/A            N/A                  1        N/A   \n",
       "3999           Boston      F              1                  1          1   \n",
       "\n",
       "     Ethnicity  ... Start 1  End 1       Role 2 Start 2  End 2  \\\n",
       "0            0  ...    2/23   9/23   Senior SWE    2/22   6/22   \n",
       "1            4  ...    7/20  12/20   Bus Driver    8/11   8/19   \n",
       "2            3  ...    2/21  12/21  ML Engineer    7/17   7/20   \n",
       "3            4  ...    6/10   6/21   Bus Driver   11/11  11/13   \n",
       "4            2  ...   12/11   1/12       Lawyer    1/18   5/18   \n",
       "...        ...  ...     ...    ...          ...     ...    ...   \n",
       "3995         1  ...    4/14   4/22   Junior SWE   10/13  10/19   \n",
       "3996         2  ...     N/A    N/A          N/A     N/A    N/A   \n",
       "3997         3  ...    2/10   2/20   Bus Driver    7/20   7/22   \n",
       "3998         4  ...    2/15   2/17       Lawyer    8/23  11/23   \n",
       "3999         3  ...    1/20  11/20   Senior SWE    4/20   4/22   \n",
       "\n",
       "              Role 3 Start 3  End 3 Resume score  Interview prediction  \n",
       "0        ML Engineer   10/22  12/22         3.18                     0  \n",
       "1             Lawyer    7/15   7/16         3.95                     0  \n",
       "2         Senior SWE    5/15   5/19         5.94                     0  \n",
       "3         Senior SWE    6/10   6/12         9.74                     0  \n",
       "4     Data scientist   12/10  12/22         5.77                     1  \n",
       "...              ...     ...    ...          ...                   ...  \n",
       "3995      Junior SWE    8/22  10/22         2.79                     1  \n",
       "3996             N/A     N/A    N/A         8.99                     0  \n",
       "3997          Lawyer   12/12  12/18         3.95                     0  \n",
       "3998          Lawyer   12/18  12/19         0.65                     0  \n",
       "3999      Bus Driver    7/14   7/19         9.06                     0  \n",
       "\n",
       "[4000 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = model_predict(df)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc8a76",
   "metadata": {},
   "source": [
    "## Fairness metrics to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "984668ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Parity Difference\n",
    "def spd(sensitive_attribute, dataset, predicted_labels, majority_class, minority_class):\n",
    "    \"\"\"\n",
    "    Calculate the Statistical Parity Difference (SPD) between majority and minority classes based on predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - sensitive_attribute (str): Name of the column representing the sensitive attribute.\n",
    "    - dataset (pd.DataFrame): The dataset containing the sensitive attribute and true outcome variable.\n",
    "    - predicted_labels (pd.Series): Predicted labels for the outcome variable.\n",
    "    - majority_class: Value representing the majority class in the sensitive attribute.\n",
    "    - minority_class: Value representing the minority class in the sensitive attribute.\n",
    "\n",
    "    Returns:\n",
    "    - spd (float): Statistical Parity Difference between majority and minority classes.\n",
    "    \"\"\"\n",
    "    predicted_labels = pd.to_numeric(predicted_labels)\n",
    "    predicted_labels_series = pd.Series(predicted_labels, index=dataset.index)\n",
    "    majority = dataset[dataset[sensitive_attribute] == majority_class]\n",
    "    minority = dataset[dataset[sensitive_attribute] == minority_class]\n",
    "\n",
    "    p_majority = predicted_labels_series[majority.index].mean()\n",
    "    p_minority = predicted_labels_series[minority.index].mean()\n",
    "\n",
    "    spd_val =  p_minority - p_majority\n",
    "    return spd_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f5c5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disparate Impact\n",
    "def di(sensitive_attribute, dataset, predicted_labels, majority_class, minority_class):\n",
    "    \"\"\"\n",
    "    Calculate the Disparate Impact (DI) between majority and minority classes based on predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - sensitive_attribute (str): Name of the column representing the sensitive attribute.\n",
    "    - dataset (pd.DataFrame): The dataset containing the sensitive attribute and true outcome variable.\n",
    "    - predicted_labels (pd.Series): Predicted labels for the outcome variable.\n",
    "    - majority_class: Value representing the majority class in the sensitive attribute.\n",
    "    - minority_class: Value representing the minority class in the sensitive attribute.\n",
    "\n",
    "    Returns:\n",
    "    - di (float): Disparate Impact between majority and minority classes.\n",
    "    \"\"\"\n",
    "    predicted_labels = pd.to_numeric(predicted_labels)\n",
    "    predicted_labels_series = pd.Series(predicted_labels, index=dataset.index)\n",
    "    majority = dataset[dataset[sensitive_attribute] == majority_class]\n",
    "    minority = dataset[dataset[sensitive_attribute] == minority_class]\n",
    "\n",
    "    p_majority = predicted_labels_series[majority.index].mean()\n",
    "    p_minority = predicted_labels_series[minority.index].mean()\n",
    "\n",
    "    di_val = p_minority / p_majority\n",
    "    return di_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e44e35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.136688518175621"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spd for current dataset\n",
    "\"\"\"\n",
    "Range: The range of SPD is [-1, 1]. \n",
    "A value of -1 indicates that all favorable outcomes are allocated to the majority group, \n",
    "whereas a value of 1 indicates that all favorable outcomes are allocated to the minority group. \n",
    "Perfect Fairness: A value of 0 indicates perfect fairness, \n",
    "meaning the probability of receiving a favorable outcome is equal for both the majority and minority groups.\n",
    "\"\"\"\n",
    "\n",
    "spd(\"Gender\", df_prediction, df_prediction[\"Interview prediction\"], \"M\", \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f14068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6214990631241338"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# di for current dataset\n",
    "\"\"\"\n",
    "Range: DI is a ratio, so its range is [0, ∞). \n",
    "A value of 0 indicates extreme bias against the minority group, \n",
    "and a very high value indicates extreme bias against the majority group. \n",
    "Perfect Fairness: A DI of 1 (or close to 1) represents perfect fairness, \n",
    "suggesting that the probability of receiving a favorable outcome are equal for both groups.\n",
    "\"\"\"\n",
    "\n",
    "di(\"Gender\", df_prediction, df_prediction[\"Interview prediction\"], \"M\", \"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5d551",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "517ef9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 413\n",
      "Error: Unable to make predictions\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInterview prediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Explain the prediction\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     51\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook(show_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/lime/lime_tabular.py:360\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# along with prediction probabilities\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43myss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLIME does not currently support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier models without probability \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores. If this conflicts with your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse case, please let us know: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/datascienceinc/lime/issues/16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(yss\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Separate 'Applicant ID' from the rest of the DataFrame\n",
    "applicant_ids = df['Applicant ID']\n",
    "df_features = df.drop('Applicant ID', axis=1)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df_features, drop_first=True)\n",
    "\n",
    "# Scale the numeric features (StandardScaler expects numeric values)\n",
    "scaler = StandardScaler()\n",
    "df_encoded_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# Add 'Applicant ID' back to the DataFrame\n",
    "df_encoded_scaled_with_id = pd.DataFrame(df_encoded_scaled, columns=df_encoded.columns)\n",
    "df_encoded_scaled_with_id['Applicant ID'] = applicant_ids\n",
    "\n",
    "# Initialize the explainer for classification\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=df_encoded_scaled_with_id.drop('Applicant ID', axis=1).values,\n",
    "    feature_names=df_encoded.columns,\n",
    "    class_names=['No Interview', 'Interview'],\n",
    "    mode='classification',\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# Select an instance to explain\n",
    "instance_index = 1  # Adjust this to your specific instance\n",
    "instance = df_encoded_scaled_with_id.drop('Applicant ID', axis=1).iloc[instance_index].values\n",
    "\n",
    "\n",
    "def predict_res(data_as_np):\n",
    "    # Reshape the input data to match the original shape\n",
    "    input_df = pd.DataFrame(data_as_np, columns=df_encoded_scaled_with_id.drop('Applicant ID', axis=1).columns)\n",
    "    # Add 'Applicant ID' back to the DataFrame\n",
    "    num_rows = len(input_df)\n",
    "    input_df['Applicant ID'] = range(1, num_rows + 1)\n",
    "    # Make predictions using the model_predict function\n",
    "    predictions_df = model_predict(input_df)\n",
    "    \n",
    "    if predictions_df is None:\n",
    "        print(\"Error: Unable to make predictions\")\n",
    "        return None\n",
    "    \n",
    "    return predictions_df['Interview prediction'].values\n",
    "\n",
    "# Explain the prediction\n",
    "exp = explainer.explain_instance(\n",
    "    instance,\n",
    "    predict_res, \n",
    "    num_features=5, \n",
    "    top_labels=1\n",
    ")\n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c58b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
