{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "51a068b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22d3a4",
   "metadata": {},
   "source": [
    "## Generating data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fa0533fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential schools for datapoints \n",
    "schools = ['Brown University', 'Columbia University', 'SUNY Binghamton University', 'SUNY New Paltz',\n",
    "           'Providence College','Rhode Island School of Design', 'Bentley University', 'Colgate University']\n",
    "\n",
    "# potential gpas for datapoints \n",
    "gpa = np.arange(1.2,4.1,0.1,dtype=float)\n",
    "\n",
    "# degree options for datapoints \n",
    "degrees = ['Bachelors','Masters','Phd']\n",
    "\n",
    "# potential locations for datapoints \n",
    "locations = ['Providence','Boston','New York City','Los Angeles','Miami','Chicago', 'Detroit', 'Washington D.C.']\n",
    "\n",
    "# potential genders \n",
    "gender = ['M', 'F', 'N/A']\n",
    "\n",
    "# potential veteran status \n",
    "veteran = ['0','1','N/A']\n",
    "\n",
    "# potential work authorization\n",
    "work_ath = ['0','1']\n",
    "\n",
    "# potential value for disability \n",
    "disability = ['0','1','N/A']\n",
    "\n",
    "# potential ethnicities \n",
    "ethnicity = ['0','1','2','3','4']\n",
    "\n",
    "# potential roles \n",
    "roles = ['Junior SWE', 'Senior SWE','Data scientist','Lawyer','ML Engineer','N/A', 'Chef','Bus Driver']\n",
    "\n",
    "# master list for all attributes not include roles \n",
    "candidate_atts = [schools, gpa, degrees, locations, gender, veteran, work_ath, disability, ethnicity]\n",
    "\n",
    "# columns for dataframe \n",
    "COLUMNS = ['School Name','GPA','Degree','Location','Gender',\n",
    "        'Veteran status','Work authorization','Disability','Ethnicity',\n",
    "        'Role 1', 'Start 1', 'End 1','Role 2','Start 2','End 2','Role 3','Start 3','End 3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e375c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MONTHS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "COLUMNS = ['School Name', 'GPA', 'Degree', 'Location', 'Gender',\n",
    "           'Veteran status', 'Work authorization', 'Disability', 'Ethnicity',\n",
    "           'Role 1', 'Start 1', 'End 1', 'Role 2', 'Start 2', 'End 2', 'Role 3', 'Start 3', 'End 3']\n",
    "\n",
    "def generate_data(n_samples: int, candidate_atts: list, roles: list) -> pd.DataFrame:\n",
    "    all_candidates = []  # List for all datapoints\n",
    "\n",
    "    # Generate for each datapoint\n",
    "    for i in range(n_samples):\n",
    "        candidate = [i + 1]  # New candidate starting with Applicant ID\n",
    "\n",
    "        # Loop through each attribute type for given candidate\n",
    "        for attribute in candidate_atts:\n",
    "            # Pick random attribute from list\n",
    "            candidate.append(attribute[np.random.randint(0, len(attribute))])\n",
    "\n",
    "        # Generate role types\n",
    "        cand_roles = [roles[np.random.randint(0, len(roles))] for _ in range(3)]\n",
    "        role_history = []  # Candidates job history\n",
    "\n",
    "        # Loop through candidate roles to populate dates\n",
    "        for index, role in enumerate(cand_roles):\n",
    "            if role == 'N/A':\n",
    "                while len(role_history) != 9:\n",
    "                    role_history.append('N/A')\n",
    "                break\n",
    "            else:\n",
    "                start_month = MONTHS[np.random.randint(0, len(MONTHS))]\n",
    "                end_month = start_month  # Initialize end_month same as start_month\n",
    "\n",
    "                start_year = np.random.randint(10, 24)\n",
    "                range_high = 23 - start_year\n",
    "                if range_high <= 0:  # Safeguard against low >= high\n",
    "                    end_year = 23  # Set to max year if no range is available\n",
    "                else:\n",
    "                    end_year = start_year + np.random.randint(0, range_high)\n",
    "\n",
    "                # If the start year equals the end year, adjust the end month to be after the start month\n",
    "                if start_year == end_year:\n",
    "                    if start_month == 12:  # Special case where start month is December\n",
    "                        end_month = 1\n",
    "                        end_year += 1  # Increment the year if end month cannot be later\n",
    "                    else:\n",
    "                        end_month = np.random.randint(start_month + 1, 13)\n",
    "\n",
    "                start = f\"{start_month}/{start_year}\"\n",
    "                if index == 0 and np.random.rand() < 0.1:  # 10% chance to end as 'N/A'\n",
    "                    end = 'N/A'\n",
    "                else:\n",
    "                    end = f\"{end_month}/{end_year}\"\n",
    "\n",
    "                role_history.append(role)\n",
    "                role_history.append(start)\n",
    "                role_history.append(end)\n",
    "\n",
    "        candidate.extend(role_history)\n",
    "        all_candidates.append(candidate)\n",
    "\n",
    "    # Insert columns including Applicant ID at the start\n",
    "    columns_with_id = ['Applicant ID'] + COLUMNS\n",
    "    df = pd.DataFrame(all_candidates, columns=columns_with_id)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate the DataFrame\n",
    "df = generate_data(4000, candidate_atts, roles)\n",
    "\n",
    "# Convert DataFrame to JSON, one dictionary per row\n",
    "dataset_json = df.to_json(orient='records') #str type\n",
    "dataset_json = json.loads(dataset_json) #list type\n",
    "# print(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3ede53fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Applicant ID                    School Name  GPA     Degree  \\\n",
      "0             1  Rhode Island School of Design  2.2    Masters   \n",
      "1             2               Brown University  2.7    Masters   \n",
      "2             3             Providence College  3.1    Masters   \n",
      "3             4            Columbia University  3.8        Phd   \n",
      "4             5               Brown University  4.0  Bachelors   \n",
      "\n",
      "          Location Gender Veteran status Work authorization Disability  \\\n",
      "0       Providence    N/A              1                  1        N/A   \n",
      "1  Washington D.C.      M              1                  1          0   \n",
      "2           Boston      F              0                  1          1   \n",
      "3           Boston    N/A              0                  0        N/A   \n",
      "4       Providence      F            N/A                  1          1   \n",
      "\n",
      "  Ethnicity          Role 1 Start 1 End 1      Role 2 Start 2 End 2  \\\n",
      "0         1      Senior SWE    1/11  1/16  Senior SWE    6/15  7/15   \n",
      "1         3     ML Engineer    4/15  4/20  Junior SWE    9/19  9/20   \n",
      "2         2  Data scientist    2/13  2/15  Junior SWE    8/20  8/22   \n",
      "3         0             N/A     N/A   N/A         N/A     N/A   N/A   \n",
      "4         2          Lawyer    8/10  8/18         N/A     N/A   N/A   \n",
      "\n",
      "           Role 3 Start 3  End 3  \n",
      "0      Junior SWE    2/23  11/23  \n",
      "1             N/A     N/A    N/A  \n",
      "2  Data scientist    4/21   4/22  \n",
      "3             N/A     N/A    N/A  \n",
      "4             N/A     N/A    N/A  \n",
      "Applicant ID            int64\n",
      "School Name            object\n",
      "GPA                   float64\n",
      "Degree                 object\n",
      "Location               object\n",
      "Gender                 object\n",
      "Veteran status         object\n",
      "Work authorization     object\n",
      "Disability             object\n",
      "Ethnicity              object\n",
      "Role 1                 object\n",
      "Start 1                object\n",
      "End 1                  object\n",
      "Role 2                 object\n",
      "Start 2                object\n",
      "End 2                  object\n",
      "Role 3                 object\n",
      "Start 3                object\n",
      "End 3                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611ff93",
   "metadata": {},
   "source": [
    "## Sending requests to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43bf9057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applicant ID</th>\n",
       "      <th>School Name</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Location</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Veteran status</th>\n",
       "      <th>Work authorization</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>Start 1</th>\n",
       "      <th>End 1</th>\n",
       "      <th>Role 2</th>\n",
       "      <th>Start 2</th>\n",
       "      <th>End 2</th>\n",
       "      <th>Role 3</th>\n",
       "      <th>Start 3</th>\n",
       "      <th>End 3</th>\n",
       "      <th>Resume score</th>\n",
       "      <th>Interview prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10/19</td>\n",
       "      <td>12/19</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>10/23</td>\n",
       "      <td>11/23</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>4/16</td>\n",
       "      <td>4/19</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Colgate University</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Phd</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3/17</td>\n",
       "      <td>3/19</td>\n",
       "      <td>Chef</td>\n",
       "      <td>9/10</td>\n",
       "      <td>9/12</td>\n",
       "      <td>Bus Driver</td>\n",
       "      <td>5/11</td>\n",
       "      <td>5/22</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bentley University</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Boston</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11/21</td>\n",
       "      <td>11/22</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>9/13</td>\n",
       "      <td>9/17</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>11/17</td>\n",
       "      <td>11/21</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Providence College</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Providence</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SUNY New Paltz</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>F</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9/13</td>\n",
       "      <td>9/14</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>1/23</td>\n",
       "      <td>12/23</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>8/10</td>\n",
       "      <td>8/19</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3996</td>\n",
       "      <td>Brown University</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>F</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6/13</td>\n",
       "      <td>6/18</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>7/23</td>\n",
       "      <td>9/23</td>\n",
       "      <td>Senior SWE</td>\n",
       "      <td>10/11</td>\n",
       "      <td>12/11</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3997</td>\n",
       "      <td>SUNY Binghamton University</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Phd</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6/15</td>\n",
       "      <td>6/19</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3998</td>\n",
       "      <td>Bentley University</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Phd</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10/13</td>\n",
       "      <td>10/21</td>\n",
       "      <td>Junior SWE</td>\n",
       "      <td>5/21</td>\n",
       "      <td>5/22</td>\n",
       "      <td>Chef</td>\n",
       "      <td>5/21</td>\n",
       "      <td>5/22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3999</td>\n",
       "      <td>Providence College</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>New York City</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4000</td>\n",
       "      <td>Brown University</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Miami</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9/10</td>\n",
       "      <td>9/11</td>\n",
       "      <td>Senior SWE</td>\n",
       "      <td>12/16</td>\n",
       "      <td>12/19</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Applicant ID                 School Name  GPA     Degree  \\\n",
       "0                1         Columbia University  2.9  Bachelors   \n",
       "1                2          Colgate University  3.8        Phd   \n",
       "2                3          Bentley University  2.8    Masters   \n",
       "3                4          Providence College  2.9    Masters   \n",
       "4                5              SUNY New Paltz  2.1    Masters   \n",
       "...            ...                         ...  ...        ...   \n",
       "3995          3996            Brown University  1.8    Masters   \n",
       "3996          3997  SUNY Binghamton University  3.0        Phd   \n",
       "3997          3998          Bentley University  2.2        Phd   \n",
       "3998          3999          Providence College  3.9  Bachelors   \n",
       "3999          4000            Brown University  3.0  Bachelors   \n",
       "\n",
       "             Location Gender Veteran status Work authorization Disability  \\\n",
       "0     Washington D.C.      F              0                  0          0   \n",
       "1             Chicago    N/A              1                  1          0   \n",
       "2              Boston      M            N/A                  0        N/A   \n",
       "3          Providence      F              1                  1          0   \n",
       "4             Chicago      F            N/A                  1        N/A   \n",
       "...               ...    ...            ...                ...        ...   \n",
       "3995          Detroit      F            N/A                  0          1   \n",
       "3996          Chicago      F              0                  0        N/A   \n",
       "3997      Los Angeles      M              0                  0        N/A   \n",
       "3998    New York City      M            N/A                  1          0   \n",
       "3999            Miami      M            N/A                  1          0   \n",
       "\n",
       "     Ethnicity  ... Start 1  End 1          Role 2 Start 2  End 2  \\\n",
       "0            3  ...   10/19  12/19          Lawyer   10/23  11/23   \n",
       "1            1  ...    3/17   3/19            Chef    9/10   9/12   \n",
       "2            2  ...   11/21  11/22          Lawyer    9/13   9/17   \n",
       "3            0  ...     N/A    N/A             N/A     N/A    N/A   \n",
       "4            2  ...    9/13   9/14  Data scientist    1/23  12/23   \n",
       "...        ...  ...     ...    ...             ...     ...    ...   \n",
       "3995         1  ...    6/13   6/18     ML Engineer    7/23   9/23   \n",
       "3996         3  ...    6/15   6/19             N/A     N/A    N/A   \n",
       "3997         0  ...   10/13  10/21      Junior SWE    5/21   5/22   \n",
       "3998         4  ...     N/A    N/A             N/A     N/A    N/A   \n",
       "3999         1  ...    9/10   9/11      Senior SWE   12/16  12/19   \n",
       "\n",
       "              Role 3 Start 3  End 3 Resume score  Interview prediction  \n",
       "0     Data scientist    4/16   4/19         4.34                     0  \n",
       "1         Bus Driver    5/11   5/22         6.52                     0  \n",
       "2     Data scientist   11/17  11/21         4.85                     0  \n",
       "3                N/A     N/A    N/A         1.24                     0  \n",
       "4             Lawyer    8/10   8/19         5.80                     0  \n",
       "...              ...     ...    ...          ...                   ...  \n",
       "3995      Senior SWE   10/11  12/11         3.35                     0  \n",
       "3996             N/A     N/A    N/A         3.44                     1  \n",
       "3997            Chef    5/21   5/22         1.79                     1  \n",
       "3998             N/A     N/A    N/A         1.85                     1  \n",
       "3999             N/A     N/A    N/A         7.97                     1  \n",
       "\n",
       "[4000 rows x 21 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_predict(data_original):\n",
    "    \n",
    "    data = data_original.copy()\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data['GPA'] = data['GPA'].apply(lambda x: f\"{x:.2f}\")\n",
    "        data = data.to_dict(orient='records')\n",
    "    # Serialize the input data to JSON\n",
    "    dataset = json.dumps(data)\n",
    "    \n",
    "    # Define the headers for JSON content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Call the first API - resume scorer\n",
    "    resume_url = 'https://jennjwang.pythonanywhere.com'\n",
    "    resume_response = requests.post(resume_url, data=dataset, headers=headers)\n",
    "    resume_response_data = json.loads(resume_response.text)\n",
    "    resume_predictions = json.loads(resume_response_data['prediction'])\n",
    "    resume_score_map = {item['applicant_id']: item['score'] for item in resume_predictions}\n",
    "\n",
    "    # Update the input data with the resume score\n",
    "    for applicant in data:\n",
    "        applicant_id = str(applicant['Applicant ID'])\n",
    "        applicant['Resume score'] = resume_score_map.get(applicant_id, None)\n",
    "    \n",
    "    # Serialize the updated data for the next API call\n",
    "    updated_dataset = json.dumps(data)\n",
    "    \n",
    "    # Call the second API - candidate scorer\n",
    "    candidate_url = 'https://heonlee.pythonanywhere.com'\n",
    "    candidate_response = requests.post(candidate_url, data=updated_dataset, headers=headers)\n",
    "    candidate_response_data = json.loads(candidate_response.text)\n",
    "    final_predictions = json.loads(candidate_response_data['prediction'])\n",
    "    final_score_map = {item['applicant_id']: item['prediction'] for item in final_predictions}\n",
    "    \n",
    "    for applicant in data:\n",
    "        applicant_id = str(applicant['Applicant ID'])\n",
    "        applicant['Interview prediction'] = final_score_map.get(applicant_id, 0)\n",
    "        \n",
    "    results = pd.DataFrame(data)\n",
    "    results['GPA'] = results['GPA'].astype(float)\n",
    "    results['Resume score'] = results['Resume score'].astype(float)\n",
    "    results['Interview prediction'] = results['Interview prediction'].astype(int)\n",
    "    \n",
    "    return results\n",
    "\n",
    "df_prediction = model_predict(df)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc8a76",
   "metadata": {},
   "source": [
    "## Fairness metrics to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "984668ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Parity Difference\n",
    "def spd(sensitive_attribute, dataset, predicted_labels, majority_class, minority_class):\n",
    "    \"\"\"\n",
    "    Calculate the Statistical Parity Difference (SPD) between majority and minority classes based on predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - sensitive_attribute (str): Name of the column representing the sensitive attribute.\n",
    "    - dataset (pd.DataFrame): The dataset containing the sensitive attribute and true outcome variable.\n",
    "    - predicted_labels (pd.Series): Predicted labels for the outcome variable.\n",
    "    - majority_class: Value representing the majority class in the sensitive attribute.\n",
    "    - minority_class: Value representing the minority class in the sensitive attribute.\n",
    "\n",
    "    Returns:\n",
    "    - spd (float): Statistical Parity Difference between majority and minority classes.\n",
    "    \"\"\"\n",
    "    predicted_labels = pd.to_numeric(predicted_labels)\n",
    "    predicted_labels_series = pd.Series(predicted_labels, index=dataset.index)\n",
    "    majority = dataset[dataset[sensitive_attribute] == majority_class]\n",
    "    minority = dataset[dataset[sensitive_attribute] == minority_class]\n",
    "\n",
    "    p_majority = predicted_labels_series[majority.index].mean()\n",
    "    p_minority = predicted_labels_series[minority.index].mean()\n",
    "\n",
    "    spd_val =  p_minority - p_majority\n",
    "    return spd_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f5c5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disparate Impact\n",
    "def di(sensitive_attribute, dataset, predicted_labels, majority_class, minority_class):\n",
    "    \"\"\"\n",
    "    Calculate the Disparate Impact (DI) between majority and minority classes based on predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - sensitive_attribute (str): Name of the column representing the sensitive attribute.\n",
    "    - dataset (pd.DataFrame): The dataset containing the sensitive attribute and true outcome variable.\n",
    "    - predicted_labels (pd.Series): Predicted labels for the outcome variable.\n",
    "    - majority_class: Value representing the majority class in the sensitive attribute.\n",
    "    - minority_class: Value representing the minority class in the sensitive attribute.\n",
    "\n",
    "    Returns:\n",
    "    - di (float): Disparate Impact between majority and minority classes.\n",
    "    \"\"\"\n",
    "    predicted_labels = pd.to_numeric(predicted_labels)\n",
    "    predicted_labels_series = pd.Series(predicted_labels, index=dataset.index)\n",
    "    majority = dataset[dataset[sensitive_attribute] == majority_class]\n",
    "    minority = dataset[dataset[sensitive_attribute] == minority_class]\n",
    "\n",
    "    p_majority = predicted_labels_series[majority.index].mean()\n",
    "    p_minority = predicted_labels_series[minority.index].mean()\n",
    "\n",
    "    di_val = p_minority / p_majority\n",
    "    return di_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5e44e35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15372753642516587"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spd for current dataset\n",
    "\"\"\"\n",
    "Range: The range of SPD is [-1, 1]. \n",
    "A value of -1 indicates that all favorable outcomes are allocated to the majority group, \n",
    "whereas a value of 1 indicates that all favorable outcomes are allocated to the minority group. \n",
    "Perfect Fairness: A value of 0 indicates perfect fairness, \n",
    "meaning the probability of receiving a favorable outcome is equal for both the majority and minority groups.\n",
    "\"\"\"\n",
    "\n",
    "spd(\"Gender\", df_prediction, df_prediction[\"Interview prediction\"], \"M\", \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f14068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.581364203836114"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# di for current dataset\n",
    "\"\"\"\n",
    "Range: DI is a ratio, so its range is [0, ∞). \n",
    "A value of 0 indicates extreme bias against the minority group, \n",
    "and a very high value indicates extreme bias against the majority group. \n",
    "Perfect Fairness: A DI of 1 (or close to 1) represents perfect fairness, \n",
    "suggesting that the probability of receiving a favorable outcome are equal for both groups.\n",
    "\"\"\"\n",
    "\n",
    "di(\"Gender\", df_prediction, df_prediction[\"Interview prediction\"], \"M\", \"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5d551",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "517ef9ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Rhode Island School of Design'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the explainer for classification, specifying categorical features\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mlime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlime_tabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLimeTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo Interview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInterview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 0 = No Interview, 1 = Interview\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify which features are categorical\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscretize_continuous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Select an instance to explain\u001b[39;00m\n\u001b[1;32m     15\u001b[0m instance_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Adjust this to your specific instance\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/lime/lime_tabular.py:258\u001b[0m, in \u001b[0;36mLimeTabularExplainer.__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Though set has no role to play if training data stats are provided\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mStandardScaler(with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_frequencies \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:839\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:875\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    874\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Rhode Island School of Design'"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "categorical_features = [i for i, col in enumerate(df.columns) if df[col].dtype == 'object']\n",
    "\n",
    "# Initialize the explainer for classification, specifying categorical features\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(df),\n",
    "    feature_names=df.columns,\n",
    "    class_names=['No Interview', 'Interview'],  # 0 = No Interview, 1 = Interview\n",
    "    mode='classification',\n",
    "    categorical_features=categorical_features,  # Specify which features are categorical\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# Select an instance to explain\n",
    "instance_index = 1  # Adjust this to your specific instance\n",
    "instance = df.drop(['Applicant ID'], axis=1).iloc[instance_index].values\n",
    "\n",
    "# Define your model_predict_api function as before\n",
    "def model_predict_api(data_as_np):\n",
    "    input_df = pd.DataFrame(data_as_np, columns=df.columns)\n",
    "    predictions_df = model_predict(input_df)\n",
    "    return predictions_df['Interview prediction'].values\n",
    "\n",
    "# Explain the prediction\n",
    "exp = explainer.explain_instance(\n",
    "    instance,\n",
    "    model_predict_api, \n",
    "    num_features=5, \n",
    "    top_labels=1\n",
    ")\n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c58b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
